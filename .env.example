# ASIAT Configuration
# Copy this file to .env and fill in your API keys

# LLM Provider: openai, gemini, anthropic, kimi, groq, ollama
ASIAT_LLM_PROVIDER=ollama

# API Keys (only needed for cloud providers, not for ollama)
# ASIAT_LLM_API_KEY=your-api-key-here
# OPENAI_API_KEY=sk-...
# GEMINI_API_KEY=...
# GOOGLE_API_KEY=...
# ANTHROPIC_API_KEY=sk-ant-...
# KIMI_API_KEY=...
# MOONSHOT_API_KEY=...
# GROQ_API_KEY=...

# Model Selection (optional, uses provider's default if not set)
# ASIAT_LLM_MODEL=gpt-4.1-mini
# ASIAT_LLM_MODEL=gemini-2.0-flash
# ASIAT_LLM_MODEL=claude-3.5-sonnet
# ASIAT_LLM_MODEL=llama3

# Custom Base URL (for Ollama or custom OpenAI-compatible endpoints)
# ASIAT_LLM_BASE_URL=http://localhost:11434

# Temperature (0.0 to 1.0)
# ASIAT_LLM_TEMPERATURE=0.7

# Organization (for OpenAI)
# ASIAT_LLM_ORGANIZATION=org-...
